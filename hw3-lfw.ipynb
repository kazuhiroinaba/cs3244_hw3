{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #3 - Labeled Faces in the Wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# On interactive mode for plotting\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9deee5edfafc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calculate mean and standard deviation for normalizaion using training and testing dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfull_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfull_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfull_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "X_train_raw = np.load('X_train.npy')\n",
    "X_test_raw = np.load('X_test.npy')\n",
    "y_train_raw = np.load('y_train.npy')\n",
    "\n",
    "# Calculate mean and standard deviation for normalizaion using training and testing dataset.\n",
    "full_train = np.concatenate((X_train_raw, X_test), axis=0)\n",
    "full_mean = np.mean(full_train)/255\n",
    "full_std = np.std(full_train)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Dataset class to wrap our dataset\n",
    "class FacesDataset(Dataset):\n",
    "    \"\"\"Faces dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.image_vectors = X\n",
    "        self.targets = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_vectors)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        one_dim_avg = self.image_vectors[idx]\n",
    "        one_dim_image = np.reshape(one_dim_avg, (50, 37)).astype('uint8')\n",
    "        im = Image.fromarray(one_dim_image)\n",
    "        imrgb = Image.merge('RGB', (im, im, im))\n",
    "\n",
    "        if self.transform:\n",
    "            imrgb = self.transform(imrgb)\n",
    "\n",
    "        return (imrgb, self.targets[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Data transformations for training and validation dataset\n",
    "# Training dataset is transformed with random horizontal flips\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Scale(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[full_mean, full_mean, full_mean],\n",
    "                             std=[full_std, full_std, full_std])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[full_mean, full_mean, full_mean],\n",
    "                             std=[full_std, full_std, full_std])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Split to training and validation dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_raw,\n",
    "                                                  y_train_raw,\n",
    "                                                  random_state=1)\n",
    "\n",
    "# Wrap training and validation dataset as Datasets\n",
    "faces_datasets = {\n",
    "    'train': FacesDataset(X_train, y_train,\n",
    "                          transform=data_transforms['train']),\n",
    "    'val': FacesDataset(X_val, y_val, transform=data_transforms['val'])\n",
    "}\n",
    "\n",
    "# Create Dataloaders for training and validation dataset\n",
    "dataloaders = {x: DataLoader(faces_datasets[x], batch_size=4,\n",
    "                             shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "\n",
    "# Size of training and validation dataset\n",
    "dataset_sizes = {x: len(faces_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "# Checks if GPU is available\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    # Starts recording time\n",
    "    since = time.time()\n",
    "    \n",
    "    # Keeps track of best parameters and f1 score from validation phase\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Train and validate for each epoch\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            # Keeps track of epoch loss, labels vs predictions\n",
    "            running_loss = 0.0\n",
    "            running_labels = torch.LongTensor()\n",
    "            running_predictions = torch.LongTensor()\n",
    "\n",
    "            # Iterate data using dataloaders\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs, labels = data\n",
    "\n",
    "                # Wrap inputs and labels in Variables\n",
    "                if use_gpu:\n",
    "                    inputs = Variable(inputs.cuda())\n",
    "                    labels = Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward and loss calculation\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward and optimize if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                running_loss += loss.data[0]\n",
    "                running_labels = torch.cat((running_labels, labels.data), 0)\n",
    "                running_predictions = torch.cat((running_predictions, preds), 0)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            \n",
    "            # Calculate f1_score using true labels and predictions\n",
    "            epoch_f1 = f1_score(running_labels.numpy(), running_predictions.numpy(), average='macro')\n",
    "\n",
    "            print('{} Loss: {:.4f} F1: {:.4f}'.format(\n",
    "                    phase, epoch_loss, epoch_f1))\n",
    "            \n",
    "            # Update best parameters and f1 score if in validation phase\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_f1 = epoch_f1\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "        \n",
    "    # Compute total time\n",
    "    time_elasped = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "            time_elasped // 60, time_elasped % 60))\n",
    "    print('Best val F1: {:4f}'.format(best_f1))\n",
    "\n",
    "    # Return model with optimized parameters\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Visualize an image\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([full_mean, full_mean, full_mean])\n",
    "    std = np.array([full_std, full_std, full_std])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    # Pause a bit so that plots are updated\n",
    "    plt.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Display predictions for a few images with given model\n",
    "def visualize_model(model, num_images=6):\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    for i, data in enumerate(dataloaders['val']):\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "\n",
    "        for j in range(inputs.size()[0]):\n",
    "            images_so_far += 1\n",
    "            ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "            ax.axis('off')\n",
    "            ax.set_title('predicted: {}'.format(preds[j]))\n",
    "            imshow(inputs.cpu().data[j])\n",
    "\n",
    "            if images_so_far == num_images:\n",
    "                return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Transfer learning of rsnet34 model is used\n",
    "model_ft = models.resnet34(pretrained=True)\n",
    "\n",
    "# Swap out the last layer\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 7)\n",
    "\n",
    "# Loss is calculated using cross entropy\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Parameters are optimized using stochastic gradient descent\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Set step size and decay for learning rate\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "num_epochs = 25\n",
    "\n",
    "# Train model\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs)\n",
    "\n",
    "# Display predictions for a few images with trained model\n",
    "visualize_model(model_ft)\n",
    "\n",
    "# Off interactive mode for plotting\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model parameters only\n",
    "torch.save(model_ft.state_dict(), 'resnet34_{}epochs.pt'.format(num_epochs))\n",
    "\n",
    "# Save entire model\n",
    "torch.save(model_ft, 'resnet34_{}epochs.model'.format(num_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict classes of dataset with given model\n",
    "def predict(X, model):\n",
    "    dataset = FacesDataset(X, np.zeros(X.shape),\n",
    "                                transform=data_transforms['val'])\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=4, num_workers=4)\n",
    "\n",
    "    results = np.array([])\n",
    "\n",
    "    for i, data in enumerate(tqdm(dataloader)):\n",
    "            inputs, _ = data\n",
    "            if use_gpu:\n",
    "                inputs = Variable(inputs.cuda())\n",
    "            else:\n",
    "                inputs = Variable(inputs)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            results = np.append(results, preds.numpy())\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict classes of test dataset\n",
    "predictions = predict(X_test_raw, torch.load('resnet34_25epochs.model'))\n",
    "\n",
    "# Save predictions of test dataset as csv\n",
    "with open('output34_25.csv', 'w') as f:\n",
    "    f.write('ImageId,PredictedClass\\n')\n",
    "    for i in range(len(X_test_raw)):\n",
    "        f.write('{},{}\\n'.format(i, int(predictions[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate training performance\n",
    "train_preds = predict(X_train_raw, torch.load('resnet34_25epochs.model'))\n",
    "train_f1 = f1_score(y_train_raw, train_preds, average='macro')\n",
    "print('Training performance')\n",
    "print('F1: {}'.format(train_f1))"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
